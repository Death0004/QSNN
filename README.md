# QSNN

From this paper: https://www.sciencedirect.com/science/article/pii/S0925231222001473#s0070

QUOTES FROM THE PAPER: 

"In this paper, we proposed QSNN, in which we design and implement a quantum computing algorithm for the moment localizations of threshold crossings with the highest computational complexity in the classic SNN. More specifically, we proposed the QUIP algorithm to calculate the unsigned inner products converted from the moment localizations of threshold crossings. Then, We gave complete proof of the original success probability and calculation accuracy of QSNN. To further improve the minimum success probability, we used a slack condition and slight repetitions to improve the minimum success probability to nearly 100%. Through analysis, it can be verified that, QSNN outperforms the classic SNN in computational complexity. The computational complexity of QSNN is log-polynomial to the data dimension, while the computational complexity of the classic SNN is linear to the data dimension. This suggests that our quantum algorithm can significantly accelerate SNNs, even for those with extremely high input dimensions. To verify our mathematical proof of the minimum success probability and the calculation accuracy, we do numerical simulations by configuring different numbers m of qubits in the control register. We found that m not impact the minimum success probability, however, can significantly improve the calculation accuracy. This suggests that our QSNN can meet the requirements of arbitrary computational accuracy. We also gradually increase the repetitions to see the improvements of the minimum success probability, and we found that when the repetitions _q_ = 11, the minimum success probability reaches 0.998. Additionally, we use our QSNN to solve the real-world image classification tasks on two datasets with different noise levels. The experimental results verify the feasibility and the robustness of our QSNN."

"Though our QSNN is based on a specific SNN model, Tempotron, the idea of using quantum computers to accelerate other kinds of SNN models is also feasible. According to the aforementioned description, the SNN models which can be accelerated by using quantum computers need to satisfy the following characteristics: (1) The basic unit of the SNN models is a LIF spiking neuron. (2) The spiking neuron generates stimuli according to whether the local maximum potential crosses the threshold potential."

"The other learning rules of SNNs adjust the weight according to the features of the stimuli. For example, Spike-Timing-Dependent Plasticity (STDP) algorithm requires the information of two or more stimuli intervals [36]. On the other hand, some SNN models do not use the local maximum potential. For example, the dendritic event-based processing (DEP) algorithm utilizes average membrane voltage over a period of time as an indicator to adjust the weight [8], [29]. Thus, its acceleration approach using quantum computers needs to further explore."



